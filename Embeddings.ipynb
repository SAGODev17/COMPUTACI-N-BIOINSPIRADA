{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAGODev17/COMPUTACI-N-BIOINSPIRADA/blob/main/Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##üßÆ Embeddings\n",
        "Un embedding convierte un texto en un vector num√©rico (lista de floats) que captura su significado sem√°ntico. Esto permite comparar textos, hacer b√∫squedas sem√°nticas, clustering, clasificaci√≥n, etc.\n"
      ],
      "metadata": {
        "id": "5JUNmAQ9YRky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Funcionamiento de los Embeddings\n",
        "\n",
        "## üìã Proceso Principal\n",
        "\n",
        "```\n",
        "üìù TEXTO DE ENTRADA\n",
        "\"El gato est√° muy feliz\"\n",
        "          ‚¨áÔ∏è\n",
        "üîß PREPROCESAMIENTO\n",
        "Limpieza ‚Ä¢ Normalizaci√≥n ‚Ä¢ Min√∫sculas\n",
        "          ‚¨áÔ∏è\n",
        "‚úÇÔ∏è TOKENIZACI√ìN  \n",
        "[\"el\", \"gato\", \"est√°\", \"muy\", \"feliz\"]\n",
        "          ‚¨áÔ∏è\n",
        "ü§ñ MODELO DE EMBEDDING\n",
        "BERT | Word2Vec | OpenAI | Sentence-BERT\n",
        "          ‚¨áÔ∏è\n",
        "üìä VECTOR NUM√âRICO\n",
        "[0.2, -0.5, 0.8, 0.1, ..., 0.3]\n",
        "Dimensiones: 50-4096\n",
        "          ‚¨áÔ∏è\n",
        "üíæ BASE DE DATOS DE VECTORES\n",
        "Almacenamiento para b√∫squedas futuras\n",
        "          ‚¨áÔ∏è\n",
        "üéØ APLICACIONES\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Puntos Clave\n",
        "\n",
        "> **üéØ Idea Principal**: Los embeddings convierten texto en n√∫meros que preservan el significado, permitiendo operaciones matem√°ticas con lenguaje natural.\n",
        "\n",
        "### ‚úÖ **Ventajas**\n",
        "- Capturan relaciones sem√°nticas\n",
        "- Permiten b√∫squedas por significado\n",
        "- Funcionan con algoritmos de ML\n",
        "- Escalan a grandes vol√∫menes\n",
        "\n",
        "### ‚ö†Ô∏è **Consideraciones**\n",
        "- Requieren gran cantidad de datos\n",
        "- Los modelos son espec√≠ficos al dominio\n",
        "- Pueden tener sesgos del entrenamiento\n",
        "- Dimensionalidad alta = m√°s recursos\n"
      ],
      "metadata": {
        "id": "umLTPQnPWpoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Aplicaciones Principales\n",
        "\n",
        "### üîç **B√∫squeda por Similitud**\n",
        "```\n",
        "Vector Consulta ‚Üí Comparar ‚Üí Calcular Similitud ‚Üí Resultados Ordenados\n",
        "                    ‚Üì\n",
        "            Base de Vectores\n",
        "```\n",
        "\n",
        "### üè∑Ô∏è **Clasificaci√≥n**\n",
        "```\n",
        "Vector Embedding ‚Üí Red Neuronal ‚Üí Categor√≠a Predicha\n",
        "```\n",
        "\n",
        "### üîó **Clustering**\n",
        "```\n",
        "M√∫ltiples Vectores ‚Üí Algoritmo Agrupamiento ‚Üí Grupos Tem√°ticos\n",
        "                        (K-means, DBSCAN)\n",
        "```\n",
        "\n",
        "### üí° **Recomendaciones**\n",
        "```\n",
        "Vector Usuario ‚Üí Buscar Similares ‚Üí Filtrar ‚Üí Items Recomendados\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## üõ†Ô∏è Modelos Populares\n",
        "\n",
        "| `task_type`             | ¬øCu√°ndo usarlo?                                                                                               | Algoritmos t√≠picos usados                      |\n",
        "| ----------------------- | ------------------------------------------------------------------------------------------------------------- | ---------------------------------------------- |\n",
        "| `\"retrieval_document\"`  | Cuando el texto ser√° almacenado para luego hacerle b√∫squeda (indexaci√≥n).                                     | `FAISS`, `pgvector`, `Annoy`, `ScaNN`          |\n",
        "| `\"retrieval_query\"`     | Cuando el texto es una **consulta del usuario** que se usar√° para buscar en documentos previamente embebidos. | `Cosine similarity`, `dot-product search`      |\n",
        "| `\"semantic_similarity\"` | Cuando quieres comparar dos textos y ver qu√© tan **sem√°nticamente similares** son.                            | `Cosine similarity`, `Euclidean distance`      |\n",
        "| `\"classification\"`      | Cuando usas embeddings como entrada para un **modelo de clasificaci√≥n supervisada**.                          | `LogisticRegression`, `SVM`, `XGBoost`, `NN`   |\n",
        "| `\"clustering\"`          | Cuando planeas **agrupar textos similares** sin etiquetas.                                                    | `KMeans`, `DBSCAN`, `HDBSCAN`, `t-SNE`, `UMAP` |\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Ejemplo Visual\n",
        "\n",
        "### Similitud entre Palabras\n",
        "```\n",
        "    Animales        Veh√≠culos       Emociones\n",
        "      üê±              üöó             üòä\n",
        "   \"gato\"           \"auto\"         \"feliz\"\n",
        "      üê∂              üö≤             üò¢  \n",
        "   \"perro\"        \"bicicleta\"     \"triste\"\n",
        "\n",
        "Distancia en el espacio vectorial:\n",
        "‚Ä¢ gato ‚Üî perro = 0.85 (MUY similar)\n",
        "‚Ä¢ gato ‚Üî auto = 0.12 (poco similar)\n",
        "‚Ä¢ feliz ‚Üî triste = 0.23 (opuestos)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üî¢ C√°lculo de Similitud\n",
        "\n",
        "### Similitud Coseno\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Vectores ejemplo (simplificado a 4 dimensiones)\n",
        "gato = [0.2, -0.5, 0.8, 0.1]\n",
        "perro = [0.3, -0.4, 0.7, 0.2]\n",
        "\n",
        "# F√≥rmula: cos(Œ∏) = (A¬∑B) / (|A|√ó|B|)\n",
        "similitud = np.dot(gato, perro) / (np.linalg.norm(gato) * np.linalg.norm(perro))\n",
        "print(f\"Similitud: {similitud:.3f}\")  # ‚Üí 0.891 (muy similar)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Casos de Uso Reales\n",
        "\n",
        "### 1. **B√∫squeda Sem√°ntica**\n",
        "```\n",
        "Consulta: \"mascotas peludas\"\n",
        "    ‚¨áÔ∏è\n",
        "[0.4, -0.2, 0.9, ...]\n",
        "    ‚¨áÔ∏è\n",
        "Buscar vectores similares\n",
        "    ‚¨áÔ∏è\n",
        "Resultados: \"gatos\", \"perros\", \"conejos\"\n",
        "```\n",
        "\n",
        "### 2. **Clasificaci√≥n de Sentimientos**\n",
        "```\n",
        "Texto: \"Me encanta este producto\"\n",
        "    ‚¨áÔ∏è\n",
        "Vector: [0.8, 0.3, -0.1, ...]\n",
        "    ‚¨áÔ∏è\n",
        "Red Neuronal\n",
        "    ‚¨áÔ∏è\n",
        "Resultado: POSITIVO (95% confianza)\n",
        "```\n",
        "\n",
        "### 3. **Sistema de Recomendaci√≥n**\n",
        "```\n",
        "Usuario le gusta: \"Harry Potter\"\n",
        "    ‚¨áÔ∏è\n",
        "Vector libro: [0.5, -0.3, 0.7, ...]\n",
        "    ‚¨áÔ∏è\n",
        "Buscar libros similares\n",
        "    ‚¨áÔ∏è\n",
        "Recomendar: \"El Se√±or de los Anillos\"\n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jc-4VNJBZP3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Implementaci√≥n R√°pida"
      ],
      "metadata": {
        "id": "eop16nSVXuaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xth3GnWSR00j"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "xXTU16mER4oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura tu API Key directamente (quemada)\n",
        "genai.configure(api_key=userdata.get('api_key'))"
      ],
      "metadata": {
        "id": "vXqqJvcjR6uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el modelo de embeddings\n",
        "model = genai.get_model(\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "UK9P7PtTS1k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Texto de ejemplo\n",
        "texto = \"Este es un texto de ejemplo para probar Gemini Embeddings.\""
      ],
      "metadata": {
        "id": "2AOKY-YaTAJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=texto,\n",
        "    task_type=\"retrieval_document\"  # Puedes cambiar seg√∫n tu caso de uso\n",
        ")"
      ],
      "metadata": {
        "id": "5SXaCtKCS55s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el vector\n",
        "embedding = response['embedding']"
      ],
      "metadata": {
        "id": "CbyQgtd5TEaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mostrar los resultados\n",
        "print(f\"‚úÖ Longitud del vector: {len(embedding)} dimensiones\")\n",
        "print(\"üîπ Primeras 10 dimensiones:\", embedding[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j85HAygoTH2B",
        "outputId": "b17535fa-0187-4f11-a2c6-73e6bd0224df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Longitud del vector: 768 dimensiones\n",
            "üîπ Primeras 10 dimensiones: [0.035021175, -0.012195336, -0.057214644, 0.023686739, 0.05417177, 0.0070224833, -0.007199279, -0.0465323, 0.0009668815, 0.055569224]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Recursos Adicionales\n",
        "\n",
        "- **OpenAI Embeddings**: `text-embedding-ada-002`\n",
        "- **Hugging Face**: Miles de modelos pre-entrenados\n",
        "- **Sentence Transformers**: F√°cil de usar para embeddings de oraciones\n",
        "- **FAISS/Pinecone**: Bases de datos vectoriales para b√∫squeda r√°pida\n",
        "\n",
        "---\n",
        "\n",
        "*üí° **Tip**: Empieza con modelos peque√±os como `all-MiniLM-L6-v2` para prototipos r√°pidos, luego escala a modelos m√°s grandes seg√∫n necesites mejor precisi√≥n.*"
      ],
      "metadata": {
        "id": "qJj5qEgsXaAq"
      }
    }
  ]
}